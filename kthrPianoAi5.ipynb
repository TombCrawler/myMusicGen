{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "import IPython.display as ipd\n",
    "# import fluidsynth\n",
    "from midi2audio import FluidSynth\n",
    "import glob\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pretty_midi\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Tomb added\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import sys\n",
    "from music21 import midi\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 498\n"
     ]
    }
   ],
   "source": [
    "#Download Chorales\n",
    "data_dir = pathlib.Path('/Volumes/MAGIC1/CS50/myMusicGen/data/chorales')\n",
    "if not data_dir.exists():\n",
    "  tf.keras.utils.get_file(\n",
    "      'midi',\n",
    "      origin='https://github.com/jamesrobertlloyd/infinite-bach/tree/master/data/chorales/midi',\n",
    "      extract=True,\n",
    "      cache_dir='.', cache_subdir='data',\n",
    "  )\n",
    "filenames = glob.glob(str(data_dir/'**/*.mid*'))\n",
    "print('Number of files:', len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnsupportedMidiFileException(Exception):\n",
    "  \"Unsupported MIDI File\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrongWindowSize(Exception):\n",
    "    def __init__(self, window_size):\n",
    "        self.message = f\"Window Size must be between 1 and 62!! Given size: {window_size}\"\n",
    "        super().__init__(self.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Tomb made a pretty useful function\"\"\"\n",
    "def check_pianoroll_dim(pianoroll):\n",
    "        rows = len(pianoroll)  # This gives the number of rows\n",
    "        columns = len(pianoroll[0])  # This assumes all rows have the same length\n",
    "\n",
    "        print(\"Number of rows:\", rows) # represents sequence length\n",
    "        print(\"Number of columns:\", columns) # represents the 4 octave range in midi 36-83\n",
    "        print(\"Total dimesions of this pianoroll is\", rows*columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Tomb made to check if there is a single one, all zeros, or multiple ones in the pitch vector\"\"\"\n",
    "\n",
    "def check_ones_zeros(array):\n",
    "    count_ones = np.count_nonzero(array == 1)\n",
    "    count_zeros = np.count_nonzero(array == 0)\n",
    "\n",
    "    if count_ones == 1 and count_zeros == array.size - 1:\n",
    "        # print(\"There is only one '1' and the rest are '0's in the array.\")\n",
    "        return True\n",
    "    elif count_zeros == array.size:\n",
    "        # print(\"All elements in the array are '0's.\")\n",
    "        return True\n",
    "    else:\n",
    "        # print(\"There are either multiple '1's or different values in the array.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Read_Midi 2\"\"\"\n",
    "\n",
    "def read_midi(filename, sop_alto, seqlen):\n",
    "  \n",
    "  def get_pianoroll(midi, nn_from, nn_thru, seqlen, tempo):\n",
    "    pianoroll = midi.get_piano_roll(fs=2*tempo/60) # shape(128, 1262) This is the core line which makes this matrix based on 8th note\n",
    "    if pianoroll.shape[1] < seqlen:\n",
    "        raise UnsupportedMidiFileException\n",
    "\n",
    "    pianoroll = pianoroll[nn_from:nn_thru, 0:seqlen] # (48, 64) Pinoroll's value still NOT binary since it has velocity\n",
    "    \n",
    "    binary_pianoroll = np.heaviside(pianoroll, 0) # converting as a binary matrix\n",
    "    transposed_pianoroll = np.transpose(binary_pianoroll) #(64, 48)\n",
    "    # transposed_pianoroll = np.transpose(pianoroll)\n",
    "    # return binary_pianoroll\n",
    "    return transposed_pianoroll # type numpy.ndarray\n",
    "\n",
    "  \n",
    "  # read midi file\n",
    "  midi = pretty_midi.PrettyMIDI(filename)\n",
    "\n",
    "  # An Exception error is thrown if there is a modulation(key change)\n",
    "  if len(midi.key_signature_changes) !=1:\n",
    "    raise UnsupportedMidiFileException\n",
    "\n",
    "  # The Exception error thrown when tempo changes\n",
    "  tempo_time, tempo = midi.get_tempo_changes()\n",
    "  if len(tempo) != 1:\n",
    "    raise UnsupportedMidiFileException\n",
    "  if sop_alto:\n",
    "    # The exception thrown if there are less than 2 parts\n",
    "    if len(midi.instruments) < 2:\n",
    "      raise UnsupportedMidiFileException\n",
    "    # Get pianoRoll returns numpy.ndarray\n",
    "    pr_s = get_pianoroll(midi.instruments[0], 36, 84, seqlen, tempo[0])\n",
    "    pr_a = get_pianoroll(midi.instruments[1], 36, 84, seqlen, tempo[0])\n",
    "    pr_b = get_pianoroll(midi.instruments[2], 36, 84, seqlen, tempo[0])\n",
    "    wholePart = get_pianoroll(midi, 36, 84, seqlen, tempo[0])\n",
    "    \n",
    "    \n",
    "    return pr_s, pr_a, pr_b, wholePart # All numpy.ndarray including keymode  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"read generatd midi file\"\"\"\n",
    "def read_melody_midi(filename, seqlen):\n",
    "\n",
    "    def get_pianoroll(midi, nn_from, nn_thru, seqlen, tempo):\n",
    "        pianoroll = midi.get_piano_roll(fs=2*tempo/60) # shape(128, 1262) This is the core line which makes this matrix based on 8th note\n",
    "        if pianoroll.shape[1] < seqlen:\n",
    "            raise UnsupportedMidiFileException\n",
    "\n",
    "        pianoroll = pianoroll[nn_from:nn_thru, 0:seqlen] # (48, 64) Pinoroll's value still NOT binary since it has velocity\n",
    "        \n",
    "        binary_pianoroll = np.heaviside(pianoroll, 0) # converting as a binary matrix\n",
    "        transposed_pianoroll = np.transpose(binary_pianoroll) #(64, 48)\n",
    "        \n",
    "        # print(\"trans pr\", transposed_pianoroll)\n",
    "        return transposed_pianoroll # type numpy.ndarray\n",
    "    \n",
    "     # read midi file\n",
    "    midi = pretty_midi.PrettyMIDI(filename)\n",
    "\n",
    "    # The Exception error thrown when tempo changes\n",
    "    tempo_time, tempo = midi.get_tempo_changes()\n",
    "    if len(tempo) != 1:\n",
    "        raise UnsupportedMidiFileException\n",
    "   \n",
    "    # Get pianoRoll returns numpy.ndarray\n",
    "    melody = get_pianoroll(midi.instruments[0], 36, 84, seqlen, tempo[0])\n",
    "    \n",
    "    return melody\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nah\n",
      "nah\n",
      "nah\n",
      "Number of rows: 495\n",
      "Number of columns: 64\n",
      "Total dimesions of this pianoroll is 31680\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Window\"\"\"\n",
    "\n",
    "np.set_printoptions(threshold=np.inf) # Show the entire print, esp Matrix\n",
    "\n",
    "x_all = [] # \n",
    "y_all_alt = [] \n",
    "y_all_bass=[] \n",
    "files = [] # Number of files 498 but for collected files, there are 3 files that SKIPPED so we'll only see 495 files. E.g (495, int, int)\n",
    "# keymodes = [] \n",
    "\n",
    "raw_seq_length =64\n",
    "window_size = 2\n",
    "\n",
    "try:\n",
    "  if 62 < window_size or window_size < 1:\n",
    "    raise WrongWindowSize(window_size)\n",
    "except WrongWindowSize as e:\n",
    "  print(e)  \n",
    "  sys.exit()\n",
    "\n",
    "for file in glob.glob(str(data_dir/\"**/*.mid*\")):\n",
    "  files.append(file)\n",
    "  try:\n",
    "    #make a window to get sequence \n",
    "    sop_data, alt_data, bass_data, whole_data = read_midi(file, sop_alto=True, seqlen=raw_seq_length)\n",
    "    x_all.append(sop_data)\n",
    "    y_all_alt.append(alt_data)\n",
    "    y_all_bass.append(bass_data)\n",
    "\n",
    "  # throw exception for midi data which can not be used\n",
    "  except UnsupportedMidiFileException:\n",
    "    print(\"nah\")\n",
    "\n",
    "\n",
    "print(check_pianoroll_dim(y_all_bass))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data shape (495, 64, 48)\n",
      "alt data shape (495, 64, 48)\n",
      "bass data shape (495, 64, 48)\n",
      "\n",
      "x_train shape (248, 64, 48)\n",
      "x_tet shape (247, 64, 48)\n",
      "\n",
      "y_train alt (248, 64, 48)\n",
      "y_test alt (247, 64, 48)\n",
      "|\n",
      "y_train bass (248, 64, 48)\n",
      "y_test bass (247, 64, 48)\n"
     ]
    }
   ],
   "source": [
    "input_data = np.array(x_all) \n",
    "output_data_alt = np.array(y_all_alt)\n",
    "output_data_bass=np.array(y_all_bass)\n",
    "print(\"input data shape\",input_data.shape)\n",
    "print(\"alt data shape\",output_data_alt.shape)\n",
    "print(\"bass data shape\",output_data_bass.shape)\n",
    "print(\"\")\n",
    "\n",
    "i_train, i_test = train_test_split(range(len(input_data)),test_size=int(len(input_data)/2)) \n",
    "x_train = input_data[i_train]\n",
    "x_test = input_data[i_test] \n",
    "print(\"x_train shape\",x_train.shape)\n",
    "print(\"x_tet shape\",x_test.shape)\n",
    "print(\"\")\n",
    "\n",
    "y_train_alt = output_data_alt[i_train] \n",
    "y_test_alt = output_data_alt[i_test] \n",
    "print(\"y_train alt\",y_train_alt.shape)\n",
    "print(\"y_test alt\",y_test_alt.shape)\n",
    "print(\"|\")\n",
    "\n",
    "\n",
    "y_train_bass = output_data_bass[i_train] \n",
    "y_test_bass = output_data_bass[i_test] \n",
    "print(\"y_train bass\",y_train_bass.shape)\n",
    "print(\"y_test bass\",y_test_bass.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "seq_length = x_train.shape[1] # Sequence size 64\n",
    "pitch_range = x_train.shape[2] # int 48 the pitch range\n",
    "print(x_train.shape[1])\n",
    "print(x_train.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_14 (InputLayer)       [(None, 64, 48)]             0         []                            \n",
      "                                                                                                  \n",
      " lstm_52 (LSTM)              (None, 64, 128)              90624     ['input_14[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_26 (Ba  (None, 64, 128)              512       ['lstm_52[0][0]']             \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " lstm_53 (LSTM)              (None, 64, 64)               49408     ['batch_normalization_26[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " lstm_54 (LSTM)              (None, 64, 32)               12416     ['lstm_53[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_55 (LSTM)              (None, 64, 16)               3136      ['lstm_54[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_27 (Ba  (None, 64, 16)               64        ['lstm_55[0][0]']             \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " output_alt (Dense)          (None, 64, 48)               816       ['batch_normalization_27[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " output_bass (Dense)         (None, 64, 48)               816       ['batch_normalization_27[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 157792 (616.38 KB)\n",
      "Trainable params: 157504 (615.25 KB)\n",
      "Non-trainable params: 288 (1.12 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define input layer\n",
    "input_layer = tf.keras.layers.Input(shape=(seq_length, pitch_range)) # shape=(None, 64, 48)\n",
    "# Shared layers\n",
    "lstm1 = tf.keras.layers.LSTM(units=128, return_sequences=True)(input_layer)\n",
    "batch_norm1 = tf.keras.layers.BatchNormalization()(lstm1)\n",
    "lstm2 = tf.keras.layers.LSTM(units=64, return_sequences=True)(batch_norm1)\n",
    "lstm3 = tf.keras.layers.LSTM(units=32, return_sequences=True)(lstm2)\n",
    "lstm4 = tf.keras.layers.LSTM(units=16,return_sequences=True)(lstm3)\n",
    "batch_norm2 =tf.keras.layers.BatchNormalization()(lstm4)\n",
    "\n",
    "# Output layer for alto , shape=(None, 48)\n",
    "output_alt = tf.keras.layers.Dense(pitch_range, activation='sigmoid', name='output_alt')(batch_norm2)\n",
    "\n",
    "# Output layer for bass , shape=(None, 48)\n",
    "output_bass = tf.keras.layers.Dense(pitch_range, activation='sigmoid', name='output_bass')(batch_norm2)\n",
    "\n",
    "# Define the model with two outputs\n",
    "model = tf.keras.Model(inputs=input_layer, outputs=[output_alt, output_bass])\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss={'output_alt': 'binary_crossentropy', 'output_bass': 'binary_crossentropy'}, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"./training_checkpoints/ckpt_{epoch}\",\n",
    "        save_weights_only=True\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"loss\",\n",
    "        patience=5,\n",
    "        verbose=1,\n",
    "        restore_best_weights=True\n",
    "    )]\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 64\n",
    "\n",
    "# model.evaluate(x_train, y_train, return_dict=True)\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, \n",
    "    {\"output_alt\": y_train_alt, \"output_bass\": y_train_bass}, \n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs, \n",
    "    callbacks=callbacks,\n",
    "    validation_data=(x_test,\n",
    "                      {\"output_alt\": y_test_alt, \"output_bass\":y_test_bass})\n",
    "                      )\n",
    "\n",
    "model.evaluate(x_train, \n",
    "               {\"output_alt\": y_train_alt, \"output_bass\": y_train_bass}, \n",
    "               return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 64\n",
      "Number of columns: 48\n",
      "Total dimesions of this pianoroll is 3072\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "melody_file = \"/Volumes/MAGIC1/CS50/myMusicGen/data/output_KP4.mid\"\n",
    "melody_data = read_melody_midi(melody_file, seqlen=64)\n",
    "print(check_pianoroll_dim(melody_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unused or Test code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential()\n",
    "# model.add(tf.keras.layers.LSTM(units=128, input_shape=(seq_length, pitch_range), return_sequences=True))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "# model.add(tf.keras.layers.LSTM(units=64, return_sequences=True))\n",
    "# model.add(tf.keras.layers.LSTM(units=32, return_sequences=True))\n",
    "# model.add(tf.keras.layers.LSTM(units=16))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "# model.add(tf.keras.layers.Dense(pitch_range, activation='sigmoid'))\n",
    "\n",
    "# # Compile the model\n",
    "# optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
    "# model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
