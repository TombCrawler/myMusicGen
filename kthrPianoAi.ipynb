{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import collections\n",
    "import datetime\n",
    "import fluidsynth\n",
    "import glob\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import pretty_midi\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Dict, List, Optional, Sequence, Tuple\n",
    "\n",
    "# Tomb added\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download Chorales\n",
    "data_dir = pathlib.Path('/Volumes/MAGIC1/CS50/myMusicGen/data/chorales')\n",
    "if not data_dir.exists():\n",
    "  tf.keras.utils.get_file(\n",
    "      'midi',\n",
    "      origin='https://github.com/jamesrobertlloyd/infinite-bach/tree/master/data/chorales/midi',\n",
    "      extract=True,\n",
    "      cache_dir='.', cache_subdir='data',\n",
    "  )\n",
    "filenames = glob.glob(str(data_dir/'**/*.mid*'))\n",
    "print(filenames)\n",
    "print('Number of files:', len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnsupportedMidiFileException(Exception):\n",
    "  \"Unsupported MIDI File\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqlen = 64\n",
    "vocab_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pianoroll(midi, nn_from, nn_thru, seqlen, tempo):\n",
    "    pianoroll = midi.get_piano_roll(fs=2*tempo/60) # This is the core line which makes this matrix based on 8th note\n",
    "\n",
    "    # print(f\"piano_roll.shape[1] a.k.a song length!{pianoroll.shape[1]}\")\n",
    "\n",
    "    if pianoroll.shape[1] < seqlen:\n",
    "        raise UnsupportedMidiFileException\n",
    "\n",
    "    pianoroll = pianoroll[nn_from:nn_thru, 0:seqlen] # Pinoroll's value still NOT binary since it has velocity\n",
    "    binary_pianoroll = np.heaviside(pianoroll, 0) # converting as a binary matrix\n",
    "    transposed_pianoroll = np.transpose(binary_pianoroll)\n",
    "\n",
    "\n",
    "    def check_pianoroll_dim(pianoroll):\n",
    "        rows = len(pianoroll)  # This gives the number of rows\n",
    "        columns = len(pianoroll[0])  # This assumes all rows have the same length\n",
    "\n",
    "        print(\"Number of rows:\", rows) # represents sequence length\n",
    "        print(\"Number of columns:\", columns) # represents the 4 octave range in midi 36-83\n",
    "        print(\"Total dimesions of pianoroll is\", rows*columns)\n",
    "    \n",
    "    # check_pianoroll_dim(transposed_pianoroll)\n",
    "    \n",
    "    # return binary_pianoroll\n",
    "    return transposed_pianoroll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read_Midi Explanation\n",
    "\n",
    "Get Major key(keymode=0) or Minor key(keymode=1)<br>\n",
    "key_number has values ​​from 0 to 11 for major keys and for minor keys,\n",
    "12~23 is included, <br> so by **dividing it by 12** and converting it to an integer,<br> \n",
    "\n",
    "it will be 0 if it is a major key,<br>\n",
    "it will be 1 if it is a minor key,<br>\n",
    "\n",
    "and assign it accordingly to keymode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_midi(filename, sop_alto, seqlen):\n",
    "  \n",
    "  def add_rest_nodes(pianoroll):  # If all the elemets are zero, the rest node says 1, else 0\n",
    "    rests = 1 - np.sum(pianoroll, axis=1)\n",
    "    rests = np.expand_dims(rests, 1)\n",
    "    return np.concatenate([pianoroll, rests], axis=1)\n",
    "  \n",
    "  \n",
    "  # read midi file\n",
    "  midi = pretty_midi.PrettyMIDI(filename)\n",
    "\n",
    "  # An Exception error is thrown if there is a modulation(key change)\n",
    "  if len(midi.key_signature_changes) !=1:\n",
    "    raise UnsupportedMidiFileException\n",
    "\n",
    "  # Modulate the given key to C major or C minor\n",
    "  key_number = midi.key_signature_changes[0].key_number\n",
    "  # transpose_to_c(midi, key_number)\n",
    "\n",
    "  # Get Major key(keynode=0) or Minor key(keynode=1)\n",
    "  keymode = np.array([int(key_number / 12)])\n",
    "\n",
    "  # The Exception error thrown when tempo changes\n",
    "  tempo_time, tempo = midi.get_tempo_changes()\n",
    "  if len(tempo) != 1:\n",
    "    raise UnsupportedMidiFileException\n",
    "  if sop_alto:\n",
    "    # The exception thrown if there are less than 2 parts\n",
    "    if len(midi.instruments) < 2:\n",
    "      raise UnsupportedMidiFileException\n",
    "    # Get pianoRoll binary Matrix for each of Soprano and alto parts\n",
    "    pr_s = get_pianoroll(midi.instruments[0], 36, 84, seqlen, tempo[0])\n",
    "    pr_a = get_pianoroll(midi.instruments[1], 36, 84, seqlen, tempo[0])\n",
    "    pr_b = get_pianoroll(midi.instruments[2], 36, 84, seqlen, tempo[0])\n",
    "    \n",
    "    sop_w_rest = add_rest_nodes(pr_s)\n",
    "    alt_w_rest = add_rest_nodes(pr_a)\n",
    "    bass_w_rest = add_rest_nodes(pr_b)\n",
    "    \n",
    "    # return pr_s, pr_a, pr_b, keymode\n",
    "    return sop_w_rest, alt_w_rest, bass_w_rest, keymode\n",
    "\n",
    "  else:\n",
    "    # Get a pianoroll which gathered all the parts\n",
    "    pr = get_pianoroll(midi, 36, 84, seqlen, tempo[0])\n",
    "    return pr, keymode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nah\n",
      "nah\n",
      "nah\n",
      "495\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Get the ingredients\"\"\"\n",
    "np.set_printoptions(threshold=np.inf) # Show the entire print, esp Matrix\n",
    "\n",
    "x_all = [] # shape will be (495, 64, 49) the list which stores inputs of soprano melodies\n",
    "y_all = [] # shape will be (495, 64, 49) the list which stores outputs of alto melodies\n",
    "keymodes = [] # the list which stores the key whether it is major or minor\n",
    "files = [] # stores the filenames of the MIDI files\n",
    "\n",
    "# repeat the process with all the midi files\n",
    "for f in glob.glob(str(data_dir/\"**/*.mid*\")):\n",
    "  # print(f)\n",
    "  try:\n",
    "    sop, alt, bass, keymode = read_midi(f, True, 64)\n",
    "\n",
    "    # add pianorolls which have been added rest elements to the lists\n",
    "    x_all.append(sop)\n",
    "    y_all.append(alt)\n",
    "    keymodes.append(keymode)\n",
    "    files.append(f)\n",
    "  # throw exception for midi data which can not be used\n",
    "  except UnsupportedMidiFileException:\n",
    "    print(\"nah\")\n",
    "\n",
    "n_notes = len(x_all) # Not sure if it is correct\n",
    "print(n_notes)\n",
    "\n",
    "# convert x_all and y_all into NumPy array to make them more useful later\n",
    "\n",
    "# Tomb added. These three lines of code is for getting the number of pitch range\n",
    "# The pitch range is 49 at this point as rest_node dim is added, refer to prof's docu\n",
    "x_all_np = np.array(x_all)\n",
    "print(x_all_np.shape[2])\n",
    "pitch_range = x_all_np.shape[2]\n",
    "\n",
    "# x_all = np.array(x_all)\n",
    "# y_all = np.array(y_all)\n",
    "\n",
    "# You get an error with this  code but can see the shape\n",
    "# x = pd.DataFrame(y_all)\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Creating a tf.data.Dataset from the Parsed notes\n",
    "\n",
    "Source Datasets:\n",
    "The simplest way to create a dataset is to create it from a **python list**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(64, 49), dtype=tf.float64, name=None)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_ds = tf.data.Dataset.from_tensor_slices(x_all)\n",
    "# y_ds = tf.data.Dataset.from_tensor_slices(y_all)\n",
    "# print(x_ds.element_spec)\n",
    "# for i, f in enumerate(x_ds):\n",
    "#     print(i, f.numpy())\n",
    "\n",
    "note_ds = tf.data.Dataset.from_tensor_slices(x_all)\n",
    "note_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(\n",
    "        dataset: tf.data.Dataset,\n",
    "        seq_length: int,\n",
    "        vocab_size = 128,\n",
    ") -> tf.data.Dataset:\n",
    "    \"\"\"Returns TF Dataset of sequence and label examples\"\"\"\n",
    "    seq_length = seq_length + 1\n",
    "    \n",
    "    print(dataset)\n",
    "    # Take 1 extra for the labels\n",
    "    windows = dataset.window(seq_length, shift=1, stride=1, drop_remainder=True) # stride=1 is default so nothing changed\n",
    "    # for window in windows:\n",
    "    #     print(f\"window!! {list(window.as_numpy_iterator())}\") # To see the inside of each window\n",
    "   \n",
    "    # Flat_map falltens the \"dataset of datasets\" into a dataset of tensors\n",
    "    flatten = lambda x:x.batch(batch_size=seq_length, drop_remainder=True) # lambda x:: Defines an anonymous function that takes an input x. and this function per se is assigned to the flatten variable\n",
    "    sequences = windows.flat_map(flatten) # An extra dimension will be added by this flat_map, which is the first dimension and size of batch_size which is seq_length+1\n",
    "    # for sequence in sequences:\n",
    "    #     print(f\"seq!!{sequence.numpy()}\")\n",
    "  \n",
    "\n",
    "    # Normalize note pitch\n",
    "    # For instance, if x is a list or array [a, b, c], the scaling operation i.e. division would result in [a/vocab_size, b/1.0, c/1.0].\n",
    "    # def scale_pitch(x):\n",
    "    #     x = x / [vocab_size, 1.0, 1.0]\n",
    "    #     return x\n",
    "    \n",
    "    # # Split the labels\n",
    "    # def split_labels(sequences): # To separates the inputs from the labels within each sequence. It returns the normalized inputs and the labels.\n",
    "    #     inputs = sequences[:-1]\n",
    "    #     labels_dense = sequences[-1]\n",
    "    #     labels = {key:labels_dense[i] for i, key in enumerate(key_order)} # the key_order is a global variable. \n",
    "\n",
    "    #     return scale_pitch(inputs), labels\n",
    "    \n",
    "    # # In Python, if you're using map from tf.data.Dataset, the map function allows you to apply a transformation to each element of the dataset.\n",
    "    # # Meaning you do not have to pass in an argument to the split_labels function even tho it expects an argumment\n",
    "    # return sequences.map(split_labels, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_TensorSliceDataset element_spec=TensorSpec(shape=(64, 49), dtype=tf.float64, name=None)>\n",
      "TensorSpec(shape=(65, 64, 49), dtype=tf.float64, name=None)\n"
     ]
    }
   ],
   "source": [
    "seq_ds = create_sequences(note_ds, seqlen, vocab_size) # Vocab size is not used yet as I do not know how to handle normlization with this data\n",
    "\n",
    "print(seq_ds.element_spec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elm = 2\n",
    "# for seq in x_seq_ds.take(1):\n",
    "\n",
    "#   print('sequence shape:', seq.shape)\n",
    "#   print(f'sequence elements (first {elm}):', seq[0: elm]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorSpec(shape=(65, 64, 49), dtype=tf.float64, name=None)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "buffer_size = n_notes - seqlen\n",
    "\n",
    "train_ds = (seq_ds\n",
    "            .shuffle(buffer_size)\n",
    "            # .batch(batch_size, drop_remainder=True)\n",
    "            .cache()\n",
    "            .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "            )\n",
    "\n",
    "print(train_ds.element_spec) # (batch_size, seqlen, pitch_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 64, 49)]          0         \n",
      "                                                                 \n",
      " lstm_25 (LSTM)              (None, 64, 128)           91136     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 64, 1)             129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91265 (356.50 KB)\n",
      "Trainable params: 91265 (356.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (seqlen, pitch_range) # (64, 49)\n",
    "learning_rate = 0.005\n",
    "\n",
    "inputs = tf.keras.Input(input_shape)\n",
    "x = tf.keras.layers.LSTM(128, input_shape=input_shape, return_sequences=True)(inputs)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "        from_logits=True) # To set True automatically adds softmax\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "metrics = tf.keras.metrics.CategoricalCrossentropy()\n",
    "\n",
    "model.compile(loss=loss,\n",
    "              optimizer=optimizer,\n",
    "              metrics=[metrics])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 1s 646us/step - loss: 0.0000e+00 - categorical_crossentropy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.0, 'categorical_crossentropy': 0.0}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = model.evaluate(train_ds, return_dict=True)\n",
    "losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --Experimental or Unused code Below-- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check the dimension of the matrix'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Check the dimension of the matrix\"\"\"\n",
    "\n",
    "# rows = len(training_data)\n",
    "# columns = len(training_data[0]) if training_data else 0  # Assuming all rows have the same length\n",
    "\n",
    "# print(\"Shape of the list:\", rows, \"x\", columns, f\"shape{rows, columns}\")\n",
    "# print(\"The total dimension of this matrx is:\", rows*columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_midi(filename, sop_alto, seqlen):\n",
    "#   midi = pretty_midi.PrettyMIDI(filename)\n",
    "\n",
    "#   if len(midi.key_signature_changes) !=1: # An Exception error is thrown if there is a modulation(key change)\n",
    "#     raise UnsupportedMidiFileException\n",
    "\n",
    "#   key_number = midi.key_signature_changes[0].key_number # explained in the text\n",
    "#   keymode = np.array([int(key_number / 12)])\n",
    "\n",
    "  \n",
    "#   _, tempo = midi.get_tempo_changes() # _ can be written as tempo_time but won't be used w/in this function\n",
    "#   if len(tempo) != 1: # counting the number of elements in the tempo array. # The Exception error thrown when tempo changes\n",
    "#     raise UnsupportedMidiFileException\n",
    "\n",
    "#   if sop_alto: # The argument is coming in as boolean, True or False\n",
    "#     if len(midi.instruments) < 2: # The exception thrown if there are less than 2 parts\n",
    "#       raise UnsupportedMidiFileException\n",
    "\n",
    "#     # Get pianoRoll binary Matrix for each of Soprano, alto, bass parts\n",
    "#     pr_s = get_pianoroll(midi.instruments[0], 36, 84, seqlen, tempo[0]) # Get pianoroll's arguments (midi, nn_from, nn_thru, seqlen, tempo):\n",
    "#     pr_a = get_pianoroll(midi.instruments[1], 36, 84, seqlen, tempo[0])\n",
    "#     pr_b = get_pianoroll(midi.instruments[2], 36, 84, seqlen, tempo[0])\n",
    "\n",
    "#     # return pr_s, keymode\n",
    "#     return pr_s, pr_a, pr_b, keymode \n",
    "    \n",
    "\n",
    "#   else:\n",
    "#     # Get a pianoroll which gathered all the parts\n",
    "#     pr = get_pianoroll(midi, 36, 84, seqlen, tempo[0])\n",
    "#     return pr, keymode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_rest_nodes(pianoroll):  # If all the elemets are zero, the rest node says 1, else 0\n",
    "#   print(\"SUM!\",np.sum(pianoroll, axis=1))\n",
    "#   import sys\n",
    "#   sys.exit()\n",
    "#   rests = 1 - np.sum(pianoroll, axis=1)\n",
    "#   rests = np.expand_dims(rests, 1)\n",
    "\n",
    "#   return np.concatenate([pianoroll, rests], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = [] # the len is 496\n",
    "\n",
    "# for each_file in glob.glob(str(data_dir/\"**/*.mid*\")):\n",
    "#   try:\n",
    "#      sop, keymode = read_midi(each_file, False, seqlen)\n",
    "#      training_data.append(add_rest_nodes(sop))\n",
    "     \n",
    "#   except UnsupportedMidiFileException:\n",
    "#      print(\"Nah\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'About tfp, tensorflow probability'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"About tfp, tensorflow probability\"\"\"\n",
    "# import tensorflow_probability as tfp\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # Create a normal distribution with mean 0 and standard deviation 1\n",
    "# normal_dist = tfp.distributions.Normal(loc=0., scale=1.)\n",
    "\n",
    "# # Sample from the distribution\n",
    "# samples = normal_dist.sample(1)  # Get 10 samples from the distribution\n",
    "\n",
    "# # Compute log probability of a value\n",
    "# log_prob = normal_dist.log_prob(0.9)  # Compute log probability of 0.5 in the distribution\n",
    "\n",
    "# # Print the samples and log probability\n",
    "# print(\"Samples:\", samples)\n",
    "# print(\"Log Probability of 0.5:\", log_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'About flat_map by tf.data.Dataset'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"About flat_map by tf.data.Dataset\"\"\"\n",
    "# BATCH_SIZE1=1\n",
    "# dataset = tf.data.Dataset.from_tensor_slices(\n",
    "#           [[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "# print(dataset.element_spec)\n",
    "# batched = dataset.batch(batch_size=BATCH_SIZE1, drop_remainder=True)\n",
    "# print(batched)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"About model size. This gets the error so gotta figure later\"\"\"\n",
    "\n",
    "# model = tf.keras.Sequential()\n",
    "# model.add(tf.keras.layers.LSTM(128, input_shape=(10, 20, 30)))\n",
    "# model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "# model.compile(optimizer='adam', loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 5, 4)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "inputs = tf.random.normal([7, 5, 4])\n",
    "lstm = tf.keras.layers.LSTM(4, return_sequences=True)\n",
    "output = lstm(inputs)\n",
    "print(output.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
