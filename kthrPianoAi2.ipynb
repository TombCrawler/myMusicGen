{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import collections\n",
    "import datetime\n",
    "import fluidsynth\n",
    "import glob\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pretty_midi\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Dict, List, Optional, Sequence, Tuple\n",
    "\n",
    "# Tomb added\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download Chorales\n",
    "data_dir = pathlib.Path('/Volumes/MAGIC1/CS50/myMusicGen/data/chorales')\n",
    "if not data_dir.exists():\n",
    "  tf.keras.utils.get_file(\n",
    "      'midi',\n",
    "      origin='https://github.com/jamesrobertlloyd/infinite-bach/tree/master/data/chorales/midi',\n",
    "      extract=True,\n",
    "      cache_dir='.', cache_subdir='data',\n",
    "  )\n",
    "filenames = glob.glob(str(data_dir/'**/*.mid*'))\n",
    "print(filenames)\n",
    "print('Number of files:', len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnsupportedMidiFileException(Exception):\n",
    "  \"Unsupported MIDI File\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Tomb made a pretty useful function\"\"\"\n",
    "def check_pianoroll_dim(pianoroll):\n",
    "        rows = len(pianoroll)  # This gives the number of rows\n",
    "        columns = len(pianoroll[0])  # This assumes all rows have the same length\n",
    "\n",
    "        print(\"Number of rows:\", rows) # represents sequence length\n",
    "        print(\"Number of columns:\", columns) # represents the 4 octave range in midi 36-83\n",
    "        print(\"Total dimesions of this pianoroll is\", rows*columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pianoroll(midi, nn_from, nn_thru, seqlen, tempo):\n",
    "    pianoroll = midi.get_piano_roll(fs=2*tempo/60) # This is the core line which makes this matrix based on 8th note\n",
    "\n",
    "    # print(f\"piano_roll.shape[1] a.k.a song length!{pianoroll.shape[1]}\")\n",
    "\n",
    "    if pianoroll.shape[1] < seqlen:\n",
    "        raise UnsupportedMidiFileException\n",
    "\n",
    "    pianoroll = pianoroll[nn_from:nn_thru, 0:seqlen] # (48, 64) Pinoroll's value still NOT binary since it has velocity\n",
    "    binary_pianoroll = np.heaviside(pianoroll, 0) # converting as a binary matrix\n",
    "    transposed_pianoroll = np.transpose(binary_pianoroll) #(64, 48)\n",
    "     \n",
    "    # return binary_pianoroll\n",
    "    return transposed_pianoroll # type numpy.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_midi(filename, sop_alto, seqlen):\n",
    "  \n",
    "  def add_rest_nodes(pianoroll):  # If all the elemets are zero, the rest node says 1, else 0\n",
    "    rests = 1 - np.sum(pianoroll, axis=1)\n",
    "    rests = np.expand_dims(rests, 1)\n",
    "    return np.concatenate([pianoroll, rests], axis=1)\n",
    "  \n",
    "  \n",
    "  # read midi file\n",
    "  midi = pretty_midi.PrettyMIDI(filename)\n",
    "\n",
    "  # An Exception error is thrown if there is a modulation(key change)\n",
    "  if len(midi.key_signature_changes) !=1:\n",
    "    raise UnsupportedMidiFileException\n",
    "\n",
    "  # Modulate the given key to C major or C minor\n",
    "  key_number = midi.key_signature_changes[0].key_number\n",
    "  # transpose_to_c(midi, key_number)\n",
    "\n",
    "  # Get Major key(keynode=0) or Minor key(keynode=1)\n",
    "  keymode = np.array([int(key_number / 12)])\n",
    "\n",
    "  # The Exception error thrown when tempo changes\n",
    "  tempo_time, tempo = midi.get_tempo_changes()\n",
    "  if len(tempo) != 1:\n",
    "    raise UnsupportedMidiFileException\n",
    "  if sop_alto:\n",
    "    # The exception thrown if there are less than 2 parts\n",
    "    if len(midi.instruments) < 2:\n",
    "      raise UnsupportedMidiFileException\n",
    "    # Get pianoRoll returns numpy.ndarray\n",
    "    pr_s = get_pianoroll(midi.instruments[0], 36, 84, seqlen, tempo[0])\n",
    "    pr_a = get_pianoroll(midi.instruments[1], 36, 84, seqlen, tempo[0])\n",
    "    pr_b = get_pianoroll(midi.instruments[2], 36, 84, seqlen, tempo[0])\n",
    "    \n",
    "    \n",
    "    sop_w_rest = add_rest_nodes(pr_s) \n",
    "    alt_w_rest = add_rest_nodes(pr_a)\n",
    "    bass_w_rest = add_rest_nodes(pr_b)\n",
    "    \n",
    "    # return pr_s, pr_a, pr_b, keymode\n",
    "    return sop_w_rest, alt_w_rest, bass_w_rest, keymode # All numpy.ndarray including keymode  \n",
    "\n",
    "  else:\n",
    "    #Get a pianoroll which gathered all the parts\n",
    "    pr = get_pianoroll(midi, 36, 84, seqlen, tempo[0])\n",
    "    return pr, keymode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nah\n",
      "nah\n",
      "nah\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Get the ingredients. \n",
    "Make the data(i.e manipulate the model as you tell it what you want) here for predict the 3rd note with given (x1,x2). \n",
    "Make list1 that has (xn, xn+1) pair elements \n",
    "and list2 which has (xn+2) elements\"\"\"\n",
    "\n",
    "np.set_printoptions(threshold=np.inf) # Show the entire print, esp Matrix\n",
    "\n",
    "x_all = [] #(1488960, 2) Total dim is 2977920.  1488960=495*64*47\n",
    "y_all = [] \n",
    "keymodes = [] \n",
    "files = []\n",
    "\n",
    "# n_notes = len(x_all) # 1488960. Not sure if it is correct\n",
    "# print(\"n_notes!\",n_notes)\n",
    "\n",
    "# repeat the process with all the midi files\n",
    "for file in glob.glob(str(data_dir/\"**/*.mid*\")):\n",
    "\n",
    "  try:\n",
    "    # make a window to get sequence pairs (Xn, Xn+1) -> Xn+2\n",
    "    sops_data, alt, bass, keymode = read_midi(file, True, 64)\n",
    "    for song in sops_data: # sops_data shape (64, 49)\n",
    "      for i in range(len(song)-2): # range(0, 62) as song originally len 64\n",
    "        input_sequence = song[i:i+2] # (Xn, Xn +1). print [0. 0.]  shape (2,)\n",
    "        output_target = song[i+2] # Xn + 2. print 0.0  shape ()\n",
    "        \n",
    "        x_all.append(input_sequence)\n",
    "        y_all.append(output_target)\n",
    "  # throw exception for midi data which can not be used\n",
    "  except UnsupportedMidiFileException:\n",
    "    print(\"nah\")\n",
    "\n",
    "\n",
    "input_data = np.array(x_all) # shape (1488960, 2) Total dim is 2977920.  1488960=495*64*47. <class 'numpy.ndarray'>\n",
    "output_data = np.array(y_all) # shape (1488960,). <class 'numpy.ndarray'>\n",
    "\n",
    "#Reshape input data to (number_of_samples, 2, 64, 47)\n",
    "#I made it 47 cz of the calculation 1488960=495*64*47 can only satisfy the total number while it makes sense but not sure why 47 instead of 49\n",
    "# input_data = input_data.reshape(-1, 2, 64, 47) # shape (495, 2, 64, 47)\n",
    "# # Reshape output data to (number_of_samples, 64, 47)\n",
    "# output_data = output_data.reshape(-1, 64, 47) # shape (495, 64, 47)\n",
    "\n",
    "i_train, i_test = train_test_split(range(len(input_data)),test_size=int(len(input_data)/2))\n",
    "x_train = input_data[i_train] # shape (248, 2, 64, 47)\n",
    "x_test = input_data[i_test] # shape (247, 2, 64, 47)\n",
    "y_train = output_data[i_train] # shape (248, 64, 47)\n",
    "y_test = output_data[i_test] # shape (247, 64, 47)\n",
    "\n",
    "# x_train = x_train.reshape(-1, 2, 64 * 47)\n",
    "# x_test = x_test.reshape(-1, 2, 64 * 47)\n",
    "\n",
    "# y_train = y_train.reshape(-1, 64*47)\n",
    "# y_test = y_test.reshape(-1, 64*47)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation\n",
    "-Convert to np.ndarray<br>\n",
    "-Extract train and test data<br>\n",
    "-Reshape(flatten) arrays to send to NNs<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.array(x_all) # shape (1488960, 2) Total dim is 2977920.  1488960=495*64*47. <class 'numpy.ndarray'>\n",
    "output_data = np.array(y_all) # shape (1488960,). <class 'numpy.ndarray'>\n",
    "\n",
    "#Reshape input data to (number_of_samples, 2, 64, 47)\n",
    "#I made it 47 cz of the calculation 1488960=495*64*47 can only satisfy the total number while it makes sense but not sure why 47 instead of 49\n",
    "input_data = input_data.reshape(-1, 2, 64, 47) # shape (495, 2, 64, 47)\n",
    "# Reshape output data to (number_of_samples, 64, 47)\n",
    "output_data = output_data.reshape(-1, 64, 47) # shape (495, 64, 47)\n",
    "\n",
    "i_train, i_test = train_test_split(range(len(input_data)),test_size=int(len(input_data)/2))\n",
    "x_train = input_data[i_train] # shape (248, 2, 64, 47)\n",
    "x_test = input_data[i_test] # shape (247, 2, 64, 47)\n",
    "y_train = output_data[i_train] # shape (248, 64, 47)\n",
    "y_test = output_data[i_test] # shape (247, 64, 47)\n",
    "\n",
    "x_train = x_train.reshape(-1, 2, 64 * 47)\n",
    "x_test = x_test.reshape(-1, 2, 64 * 47)\n",
    "\n",
    "y_train = y_train.reshape(-1, 64*47)\n",
    "y_test = y_test.reshape(-1, 64*47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_length = x_train.shape[1] # 2 -> 時系列の長さ(時間方向の要素数)\n",
    "# input_dim = x_train.shape[2] # 64 -> 入力の各要素の次元数\n",
    "# output_dim = y_train.shape[2] # 47-> 出力の各要素の次元数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step - loss: 512.5793 - accuracy: 0.0000e+00\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 13ms/step - loss: 511.5201 - accuracy: 0.0000e+00 - val_loss: 508.7806 - val_accuracy: 0.0040\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 502.9782 - accuracy: 0.0000e+00 - val_loss: 493.0836 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 480.9799 - accuracy: 0.0000e+00 - val_loss: 467.4860 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 456.6798 - accuracy: 0.0000e+00 - val_loss: 449.9346 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 443.2662 - accuracy: 0.0000e+00 - val_loss: 442.2012 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 437.1392 - accuracy: 0.0000e+00 - val_loss: 438.6164 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 433.8093 - accuracy: 0.0000e+00 - val_loss: 436.5982 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 431.7993 - accuracy: 0.0000e+00 - val_loss: 435.4269 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 430.5196 - accuracy: 0.0000e+00 - val_loss: 434.7188 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 429.6622 - accuracy: 0.0000e+00 - val_loss: 434.3941 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 429.2022 - accuracy: 0.0000e+00 - val_loss: 434.4082 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 429.1373 - accuracy: 0.0000e+00 - val_loss: 434.6851 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 429.2711 - accuracy: 0.0000e+00 - val_loss: 435.1530 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 429.5373 - accuracy: 0.0000e+00 - val_loss: 435.7672 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 430.0336 - accuracy: 0.0000e+00 - val_loss: 436.5787 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 430.7164 - accuracy: 0.0000e+00 - val_loss: 437.5880 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 431.6636 - accuracy: 0.0000e+00 - val_loss: 438.6570 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 432.6020 - accuracy: 0.0000e+00 - val_loss: 439.8210 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 433.5276 - accuracy: 0.0000e+00 - val_loss: 441.0458 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 434.6076 - accuracy: 0.0000e+00 - val_loss: 442.4613 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 435.7883 - accuracy: 0.0000e+00 - val_loss: 443.9205 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 437.1079 - accuracy: 0.0000e+00 - val_loss: 445.4570 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 438.5569 - accuracy: 0.0000e+00 - val_loss: 447.0711 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 440.0486 - accuracy: 0.0000e+00 - val_loss: 448.7758 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 441.5116 - accuracy: 0.0000e+00 - val_loss: 450.5367 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 443.1111 - accuracy: 0.0000e+00 - val_loss: 452.3616 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 430.0048 - accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(x_train, y_train, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/MAGIC1/CS50/myMusicGen/venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Volumes/MAGIC1/CS50/myMusicGen/venv/lib/python3.9/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/Volumes/MAGIC1/CS50/myMusicGen/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Volumes/MAGIC1/CS50/myMusicGen/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Volumes/MAGIC1/CS50/myMusicGen/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/Volumes/MAGIC1/CS50/myMusicGen/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:147\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m--> 147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mconcrete_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m/Volumes/MAGIC1/CS50/myMusicGen/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:359\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m current_func_context \u001b[38;5;241m=\u001b[39m function_context\u001b[38;5;241m.\u001b[39mmake_function_context()\n\u001b[1;32m    355\u001b[0m \u001b[38;5;66;03m# cache_key_deletion_observer is useless here. It's based on all captures.\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;66;03m# A new cache key will be built later when saving ConcreteFunction because\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;66;03m# only active captures should be saved.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m lookup_func_type, lookup_func_context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 359\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_canonicalized_monomorphic_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptures\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    361\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mlookup(current_func_context,\n\u001b[1;32m    362\u001b[0m                                                 lookup_func_type)\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concrete_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Volumes/MAGIC1/CS50/myMusicGen/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/function_spec.py:324\u001b[0m, in \u001b[0;36mFunctionSpec.make_canonicalized_monomorphic_type\u001b[0;34m(self, args, kwargs, captures)\u001b[0m\n\u001b[1;32m    316\u001b[0m   captures \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m    318\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    319\u001b[0m     function_type_lib\u001b[38;5;241m.\u001b[39msanitize_arg_name(name): value\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    321\u001b[0m }\n\u001b[1;32m    323\u001b[0m _, function_type, type_context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 324\u001b[0m     \u001b[43mfunction_type_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanonicalize_to_monomorphic\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m )\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function_type, type_context\n",
      "File \u001b[0;32m/Volumes/MAGIC1/CS50/myMusicGen/venv/lib/python3.9/site-packages/tensorflow/core/function/polymorphism/function_type.py:462\u001b[0m, in \u001b[0;36mcanonicalize_to_monomorphic\u001b[0;34m(args, kwargs, default_values, captures, polymorphic_type)\u001b[0m\n\u001b[1;32m    456\u001b[0m       parameters\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    457\u001b[0m           _make_validated_mono_param(kwarg_name, arg[kwarg_name],\n\u001b[1;32m    458\u001b[0m                                      Parameter\u001b[38;5;241m.\u001b[39mKEYWORD_ONLY, type_context,\n\u001b[1;32m    459\u001b[0m                                      poly_parameter\u001b[38;5;241m.\u001b[39mtype_constraint))\n\u001b[1;32m    460\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m     parameters\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 462\u001b[0m         \u001b[43m_make_validated_mono_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoly_parameter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mtype_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mpoly_parameter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_constraint\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    466\u001b[0m capture_types \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mOrderedDict()\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m captures\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/Volumes/MAGIC1/CS50/myMusicGen/venv/lib/python3.9/site-packages/tensorflow/core/function/polymorphism/function_type.py:402\u001b[0m, in \u001b[0;36m_make_validated_mono_param\u001b[0;34m(name, value, kind, type_context, poly_type)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_validated_mono_param\u001b[39m(\n\u001b[1;32m    399\u001b[0m     name, value, kind, type_context, poly_type\n\u001b[1;32m    400\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Parameter:\n\u001b[1;32m    401\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Generates and validates a parameter for Monomorphic FunctionType.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m   mono_type \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m poly_type \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mono_type\u001b[38;5;241m.\u001b[39mis_subtype_of(poly_type):\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` was expected to be of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    406\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpoly_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmono_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Volumes/MAGIC1/CS50/myMusicGen/venv/lib/python3.9/site-packages/tensorflow/core/function/trace_type/trace_type_builder.py:125\u001b[0m, in \u001b[0;36mfrom_value\u001b[0;34m(value, context)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# Public APIs like get_concrete_function allow users to pass in specs\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# instead which need to pass through input binding etc.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_specs\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_value\u001b[39m(value: Any,\n\u001b[1;32m    126\u001b[0m                context: trace\u001b[38;5;241m.\u001b[39mTracingContext \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m trace\u001b[38;5;241m.\u001b[39mTraceType:\n\u001b[1;32m    127\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a TraceType corresponding to the value based on the context.\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    A TraceType object representing the given value.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m    137\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Assuming the shapes you've provided: x_train, x_test, y_train, y_test\n",
    "\n",
    "# Create an LSTM model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Add an LSTM layer\n",
    "model.add(tf.keras.layers.LSTM(units=64, input_shape=(2, 64*47)))  # LSTM units can be adjusted based on the complexity of the problem\n",
    "\n",
    "# Add a dense layer for output\n",
    "model.add(tf.keras.layers.Dense(64*47, activation='softmax'))  # Adjust the output shape based on your targets\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.evaluate(x_train, y_train, return_dict=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unused Code Below>>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"get inputs (Xn, Xn+1) and target (Xn+2) \"\"\"\n",
    "# def make_sequences(\n",
    "#         dataset: tf.data.Dataset,\n",
    "#         seq_length:int,\n",
    "# ) -> tf.data.Dataset:\n",
    "    \n",
    "#     seq_length = seq_length+1\n",
    "\n",
    "#     windows = dataset.window(seq_length, shift=1, stride=1, drop_remainder=True)\n",
    "#     # for w in windows:\n",
    "#     #    print(f\"window!! {list(w.as_numpy_iterator())}\")\n",
    "    \n",
    "#     flatten = lambda x: x.batch(seq_length, drop_remainder=True) # Assing lambda function to the variable \"flatten\"\n",
    "#     sequences = windows.flat_map(flatten) # Flat_map falltens the \"dataset of datasets\" into a dataset of tensors\n",
    "\n",
    "#     def split_labels(sequences):\n",
    "#         inputs = sequences[:-1] # Could not see the inside as this func got in through map_func\n",
    "#         output_dense = sequences[-1]\n",
    "#         return inputs, output_dense\n",
    "    \n",
    "#     return sequences.map(split_labels, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sop_tf_data = [] #  A list which contains (64 ,49) tf.daset elements\n",
    "# sop, alt, bass, keymode = read_midi(f, True, 64)\n",
    "# # sop = sop[0]\n",
    "# # sop_tf = tf.data.Dataset.from_tensor_slices(sop)\n",
    "# # print(list(sop_tf.as_numpy_iterator()))\n",
    "\n",
    "# for i in sop:\n",
    "#     sop_tf = tf.data.Dataset.from_tensor_slices(i)\n",
    "#     sop_tf_data.append(sop_tf)\n",
    "\n",
    "# # for t in sop_tf_data:\n",
    "#     # print(list(t.as_numpy_iterator()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_sop_tf = sop_tf_data[0]\n",
    "# seq_length = 2\n",
    "# # print(make_sequences(single_sop_tf, seq_length))\n",
    "\n",
    "# seq_ds = make_sequences(single_sop_tf, seq_length) # 47 elements each input n output\n",
    "# # type <'tensorflow _ParallelMapDataset'>\n",
    "# # print(seq_ds.element_spec)\n",
    "# # print(list(seq_ds.as_numpy_iterator())) # [(array([0., 0.]), 0.0), (array([0., 0.]), 0.0)...\n",
    "\n",
    "\n",
    "# inputList = []\n",
    "# targetList = []\n",
    "\n",
    "# #<Check the dataset elements>\n",
    "# for seq, target in seq_ds:\n",
    "#   # print('Input sequence shape:', seq.shape) # shape (2,), a one-dimensional array (vector) with a length of 2.\n",
    "#   # print('Input sequence elements:', seq[0: 1]) \n",
    "#   # print('target:', target) # shape ()\n",
    "#   # print()\n",
    "#   inputList.append(seq) # <class 'list'>\n",
    "#   targetList.append(target) # <class 'list'>\n",
    "\n",
    "# inputList = np.array(inputList) # <class 'numpy.ndarray'>. shape (47, 2), 2D matrix\n",
    "# targetList = np.array(targetList) # <class 'numpy.ndarray'> shape (47,), 1D scalar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
