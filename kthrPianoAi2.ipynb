{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import collections\n",
    "import datetime\n",
    "import fluidsynth\n",
    "import glob\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pretty_midi\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Dict, List, Optional, Sequence, Tuple\n",
    "\n",
    "# Tomb added\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download Chorales\n",
    "data_dir = pathlib.Path('/Volumes/MAGIC1/CS50/myMusicGen/data/chorales')\n",
    "if not data_dir.exists():\n",
    "  tf.keras.utils.get_file(\n",
    "      'midi',\n",
    "      origin='https://github.com/jamesrobertlloyd/infinite-bach/tree/master/data/chorales/midi',\n",
    "      extract=True,\n",
    "      cache_dir='.', cache_subdir='data',\n",
    "  )\n",
    "filenames = glob.glob(str(data_dir/'**/*.mid*'))\n",
    "print(filenames)\n",
    "print('Number of files:', len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnsupportedMidiFileException(Exception):\n",
    "  \"Unsupported MIDI File\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Tomb made a pretty useful function\"\"\"\n",
    "def check_pianoroll_dim(pianoroll):\n",
    "        rows = len(pianoroll)  # This gives the number of rows\n",
    "        columns = len(pianoroll[0])  # This assumes all rows have the same length\n",
    "\n",
    "        print(\"Number of rows:\", rows) # represents sequence length\n",
    "        print(\"Number of columns:\", columns) # represents the 4 octave range in midi 36-83\n",
    "        print(\"Total dimesions of this pianoroll is\", rows*columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pianoroll(midi, nn_from, nn_thru, seqlen, tempo):\n",
    "    pianoroll = midi.get_piano_roll(fs=2*tempo/60) # This is the core line which makes this matrix based on 8th note\n",
    "\n",
    "    # print(f\"piano_roll.shape[1] a.k.a song length!{pianoroll.shape[1]}\")\n",
    "\n",
    "    if pianoroll.shape[1] < seqlen:\n",
    "        raise UnsupportedMidiFileException\n",
    "\n",
    "    pianoroll = pianoroll[nn_from:nn_thru, 0:seqlen] # (48, 64) Pinoroll's value still NOT binary since it has velocity\n",
    "    binary_pianoroll = np.heaviside(pianoroll, 0) # converting as a binary matrix\n",
    "    transposed_pianoroll = np.transpose(binary_pianoroll) #(64, 48)\n",
    "     \n",
    "    # return binary_pianoroll\n",
    "    return transposed_pianoroll # type numpy.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_midi(filename, sop_alto, seqlen):\n",
    "  \n",
    "  def add_rest_nodes(pianoroll):  # If all the elemets are zero, the rest node says 1, else 0\n",
    "    rests = 1 - np.sum(pianoroll, axis=1)\n",
    "    rests = np.expand_dims(rests, 1)\n",
    "    return np.concatenate([pianoroll, rests], axis=1)\n",
    "  \n",
    "  \n",
    "  # read midi file\n",
    "  midi = pretty_midi.PrettyMIDI(filename)\n",
    "\n",
    "  # An Exception error is thrown if there is a modulation(key change)\n",
    "  if len(midi.key_signature_changes) !=1:\n",
    "    raise UnsupportedMidiFileException\n",
    "\n",
    "  # Modulate the given key to C major or C minor\n",
    "  key_number = midi.key_signature_changes[0].key_number\n",
    "  # transpose_to_c(midi, key_number)\n",
    "\n",
    "  # Get Major key(keynode=0) or Minor key(keynode=1)\n",
    "  keymode = np.array([int(key_number / 12)])\n",
    "\n",
    "  # The Exception error thrown when tempo changes\n",
    "  tempo_time, tempo = midi.get_tempo_changes()\n",
    "  if len(tempo) != 1:\n",
    "    raise UnsupportedMidiFileException\n",
    "  if sop_alto:\n",
    "    # The exception thrown if there are less than 2 parts\n",
    "    if len(midi.instruments) < 2:\n",
    "      raise UnsupportedMidiFileException\n",
    "    # Get pianoRoll returns numpy.ndarray\n",
    "    pr_s = get_pianoroll(midi.instruments[0], 36, 84, seqlen, tempo[0])\n",
    "    pr_a = get_pianoroll(midi.instruments[1], 36, 84, seqlen, tempo[0])\n",
    "    pr_b = get_pianoroll(midi.instruments[2], 36, 84, seqlen, tempo[0])\n",
    "    \n",
    "    \n",
    "    sop_w_rest = add_rest_nodes(pr_s) \n",
    "    alt_w_rest = add_rest_nodes(pr_a)\n",
    "    bass_w_rest = add_rest_nodes(pr_b)\n",
    "    \n",
    "    # return pr_s, pr_a, pr_b, keymode\n",
    "    return sop_w_rest, alt_w_rest, bass_w_rest, keymode # All numpy.ndarray including keymode  \n",
    "\n",
    "  else:\n",
    "    #Get a pianoroll which gathered all the parts\n",
    "    pr = get_pianoroll(midi, 36, 84, seqlen, tempo[0])\n",
    "    return pr, keymode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nah\n",
      "nah\n",
      "nah\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Get the ingredients. \n",
    "Make the data(i.e manipulate the model as you tell it what you want) here for predict the 3rd note with given (x1,x2). \n",
    "Make list1 that has (xn, xn+1) pair elements \n",
    "and list2 which has (xn+2) elements\"\"\"\n",
    "\n",
    "np.set_printoptions(threshold=np.inf) # Show the entire print, esp Matrix\n",
    "\n",
    "x_all = [] #(1488960, 2) Total dim is 2977920.  1488960=495*64*47\n",
    "y_all = [] \n",
    "keymodes = [] \n",
    "files = []\n",
    "\n",
    "# n_notes = len(x_all) # 1488960. Not sure if it is correct\n",
    "# print(\"n_notes!\",n_notes)\n",
    "\n",
    "# repeat the process with all the midi files\n",
    "for file in glob.glob(str(data_dir/\"**/*.mid*\")):\n",
    "\n",
    "  try:\n",
    "    # make a window to get sequence pairs (Xn, Xn+1) -> Xn+2\n",
    "    sops_data, alt, bass, keymode = read_midi(file, True, 64)\n",
    "    for song in sops_data: # sops_data shape (64, 49)\n",
    "      for i in range(len(song)-2): # range(0, 62) as song originally len 64\n",
    "        input_sequence = song[i:i+2] # (Xn, Xn +1). print [0. 0.]  shape (2,)\n",
    "        output_target = song[i+2] # Xn + 2. print 0.0  shape ()\n",
    "        \n",
    "        x_all.append(input_sequence)\n",
    "        y_all.append(output_target)\n",
    "  # throw exception for midi data which can not be used\n",
    "  except UnsupportedMidiFileException:\n",
    "    print(\"nah\")\n",
    "\n",
    "\n",
    "input_data = np.array(x_all) # shape (1488960, 2) Total dim is 2977920.  1488960=495*64*47. <class 'numpy.ndarray'>\n",
    "output_data = np.array(y_all) # shape (1488960,). <class 'numpy.ndarray'>\n",
    "\n",
    "#Reshape input data to (number_of_samples, 2, 64, 47)\n",
    "#I made it 47 cz of the calculation 1488960=495*64*47 can only satisfy the total number while it makes sense but not sure why 47 instead of 49\n",
    "input_data = input_data.reshape(-1, 2, 64, 47) # shape (495, 2, 64, 47)\n",
    "# Reshape output data to (number_of_samples, 64, 47)\n",
    "output_data = output_data.reshape(-1, 64, 47) # shape (495, 64, 47)\n",
    "\n",
    "i_train, i_test = train_test_split(range(len(input_data)),test_size=int(len(input_data)/2))\n",
    "x_train = input_data[i_train] # shape (248, 2, 64, 47)\n",
    "x_test = input_data[i_test] # shape (247, 2, 64, 47)\n",
    "y_train = output_data[i_train] # shape (248, 64, 47)\n",
    "y_test = output_data[i_test] # shape (247, 64, 47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = x_train.shape[1] # 2 -> 時系列の長さ(時間方向の要素数)\n",
    "input_dim = x_train.shape[2] # 64 -> 入力の各要素の次元数\n",
    "output_dim = y_train.shape[2] # 47-> 出力の各要素の次元数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unused Code Below>>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"get inputs (Xn, Xn+1) and target (Xn+2) \"\"\"\n",
    "# def make_sequences(\n",
    "#         dataset: tf.data.Dataset,\n",
    "#         seq_length:int,\n",
    "# ) -> tf.data.Dataset:\n",
    "    \n",
    "#     seq_length = seq_length+1\n",
    "\n",
    "#     windows = dataset.window(seq_length, shift=1, stride=1, drop_remainder=True)\n",
    "#     # for w in windows:\n",
    "#     #    print(f\"window!! {list(w.as_numpy_iterator())}\")\n",
    "    \n",
    "#     flatten = lambda x: x.batch(seq_length, drop_remainder=True) # Assing lambda function to the variable \"flatten\"\n",
    "#     sequences = windows.flat_map(flatten) # Flat_map falltens the \"dataset of datasets\" into a dataset of tensors\n",
    "\n",
    "#     def split_labels(sequences):\n",
    "#         inputs = sequences[:-1] # Could not see the inside as this func got in through map_func\n",
    "#         output_dense = sequences[-1]\n",
    "#         return inputs, output_dense\n",
    "    \n",
    "#     return sequences.map(split_labels, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sop_tf_data = [] #  A list which contains (64 ,49) tf.daset elements\n",
    "# sop, alt, bass, keymode = read_midi(f, True, 64)\n",
    "# # sop = sop[0]\n",
    "# # sop_tf = tf.data.Dataset.from_tensor_slices(sop)\n",
    "# # print(list(sop_tf.as_numpy_iterator()))\n",
    "\n",
    "# for i in sop:\n",
    "#     sop_tf = tf.data.Dataset.from_tensor_slices(i)\n",
    "#     sop_tf_data.append(sop_tf)\n",
    "\n",
    "# # for t in sop_tf_data:\n",
    "#     # print(list(t.as_numpy_iterator()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_sop_tf = sop_tf_data[0]\n",
    "# seq_length = 2\n",
    "# # print(make_sequences(single_sop_tf, seq_length))\n",
    "\n",
    "# seq_ds = make_sequences(single_sop_tf, seq_length) # 47 elements each input n output\n",
    "# # type <'tensorflow _ParallelMapDataset'>\n",
    "# # print(seq_ds.element_spec)\n",
    "# # print(list(seq_ds.as_numpy_iterator())) # [(array([0., 0.]), 0.0), (array([0., 0.]), 0.0)...\n",
    "\n",
    "\n",
    "# inputList = []\n",
    "# targetList = []\n",
    "\n",
    "# #<Check the dataset elements>\n",
    "# for seq, target in seq_ds:\n",
    "#   # print('Input sequence shape:', seq.shape) # shape (2,), a one-dimensional array (vector) with a length of 2.\n",
    "#   # print('Input sequence elements:', seq[0: 1]) \n",
    "#   # print('target:', target) # shape ()\n",
    "#   # print()\n",
    "#   inputList.append(seq) # <class 'list'>\n",
    "#   targetList.append(target) # <class 'list'>\n",
    "\n",
    "# inputList = np.array(inputList) # <class 'numpy.ndarray'>. shape (47, 2), 2D matrix\n",
    "# targetList = np.array(targetList) # <class 'numpy.ndarray'> shape (47,), 1D scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "# Each MNIST image batch is a tensor of shape (batch_size, 28, 28).\n",
    "# Each input sequence will be of size (28, 28) (height is treated like time).\n",
    "input_dim = 28\n",
    "\n",
    "units = 64\n",
    "output_size = 10  # labels are from 0 to 9\n",
    "\n",
    "\n",
    "# Build the RNN model\n",
    "def build_model(allow_cudnn_kernel=True):\n",
    "    # CuDNN is only available at the layer level, and not at the cell level.\n",
    "    # This means `LSTM(units)` will use the CuDNN kernel,\n",
    "    # while RNN(LSTMCell(units)) will run on non-CuDNN kernel.\n",
    "    if allow_cudnn_kernel:\n",
    "        # The LSTM layer with default options uses CuDNN.\n",
    "        lstm_layer = tf.keras.layers.LSTM(units, input_shape=(None, input_dim))\n",
    "    else:\n",
    "        # Wrapping a LSTMCell in a RNN layer will not use CuDNN.\n",
    "        lstm_layer = tf.keras.layers.RNN(\n",
    "            tf.keras.layers.LSTMCell(units), input_shape=(None, input_dim)\n",
    "        )\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            lstm_layer,\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dense(output_size),\n",
    "        ]\n",
    "    )\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train1, y_train1), (x_test1, y_test1) = mnist.load_data()\n",
    "x_train1, x_test1 = x_train1 / 255.0, x_test1 / 255.0 # (60000, 28, 28), (10000, 28, 28)\n",
    "\n",
    "sample, sample_label = x_train1[0], y_train1[0] \n",
    "print(x_train1[1])\n",
    "\"\"\"\"\n",
    "sample prints a big 2D array  and shape (28, 28), \n",
    "sample_label prints 5  and shape ()\n",
    "\n",
    "y_train prints bunch of numbers in scalar\"\"\"\n",
    "\n",
    "model = build_model(allow_cudnn_kernel=True)\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
