{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import fluidsynth\n",
    "from IPython.display import Audio\n",
    "from IPython import display\n",
    "import ipywidgets as widgets\n",
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wavfile\n",
    "import collections\n",
    "import datetime\n",
    "import fluidsynth\n",
    "import glob\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import pretty_midi\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Dict, List, Optional, Sequence, Tuple\n",
    "\n",
    "# Sampling rate for audio playback\n",
    "_SAMPLING_RATE = 44100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/MAGIC1/CS50/myMusicGen/data/aero.mid\n"
     ]
    }
   ],
   "source": [
    "# Get a single midi file\n",
    "\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "midi_url = 'https://www.midiworld.com/download/2275'\n",
    "midi_path = \"/Volumes/MAGIC1/CS50/myMusicGen/data/aero.mid\"\n",
    "data_dir = pathlib.Path(midi_path)\n",
    "if not data_dir.exists():\n",
    "  tf.keras.utils.get_file(\n",
    "      'aero.mid',\n",
    "      origin= midi_url,\n",
    "      extract=True,\n",
    "      cache_dir='.', cache_subdir='data',\n",
    "  )\n",
    "\n",
    "# The data above contains one Midi file\n",
    "filenames = str(data_dir)\n",
    "# print('Number of files:', len(filenames))\n",
    "\n",
    "# Process a MIDI file\n",
    "sample_file = filenames\n",
    "print(sample_file)\n",
    "# print(sample_file)\n",
    "\n",
    "# generate a prettyMIDI object for the sample MIDI file\n",
    "pm = pretty_midi.PrettyMIDI(sample_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo: 221.81\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# show tempo\n",
    "\n",
    "midi_data = pretty_midi.PrettyMIDI(midi_path) # load midi file\n",
    "print(f\"Tempo: {midi_data.estimate_tempo():.2f}\") # Print its goal tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01969\n",
      "0.05819\n",
      "0.22525\n",
      "0.00077\n",
      "0.14577\n",
      "0.01377\n",
      "0.07136\n",
      "0.13795\n",
      "0.00070\n",
      "0.15646\n",
      "0.00468\n",
      "0.16543\n"
     ]
    }
   ],
   "source": [
    "# Compute the relative amount of each semitone across the entire song, a proxy for key\n",
    "'''the .get_chroma() method is used to compute the chromagram of a MIDI file or a specific instrument track within the MIDI file. \n",
    "The chromagram represents the intensity of each chroma (musical pitch class) over time.'''\n",
    "total_velocity = sum(sum(midi_data.get_chroma()))\n",
    "velocities = [sum(semitone)/total_velocity for semitone in midi_data.get_chroma()]\n",
    "for i in velocities:\n",
    "    print(f\"{i:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Change pitch\n",
    "\n",
    "# # Load MIDI file into PrettyMIDI object\n",
    "# midi_data = pretty_midi.PrettyMIDI('/Volumes/MAGIC1/CS50/myMusicGen/data/mj.mid')\n",
    "\n",
    "# # Store the original drum notes\n",
    "# drum_notes = []\n",
    "# for instrument in midi_data.instruments:\n",
    "#     if instrument.is_drum:\n",
    "#         drum_notes.extend(instrument.notes)\n",
    "\n",
    "# # Shift pitch of non-drum instruments\n",
    "# for instrument in midi_data.instruments:\n",
    "#     if not instrument.is_drum:\n",
    "#         for note in instrument.notes:\n",
    "#             note.pitch += 0\n",
    "\n",
    "# # Create a new instrument track for the preserved drum notes\n",
    "# drum_instrument = pretty_midi.Instrument(program=0, is_drum=True)\n",
    "# drum_instrument.notes = drum_notes\n",
    "\n",
    "# # Add the preserved drum track back to the MIDI data\n",
    "# midi_data.instruments.append(drum_instrument)\n",
    "\n",
    "# # Synthesize the resulting MIDI data using sine waves\n",
    "# audio_data = midi_data.synthesize()\n",
    "\n",
    "# # Play the audio data\n",
    "# Audio(data=audio_data, rate=midi_data.synthesize().shape[0] / midi_data.get_end_time())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suceeded to extract only drums and meldies separately\n",
    "# and Both instruments play simultaneously, each coming out of its respective stereo. \n",
    "# And can manipulate the pitch for the non-drum insts\n",
    "\n",
    "# Load MIDI file into PrettyMIDI object\n",
    "midi_data = pretty_midi.PrettyMIDI(midi_path)\n",
    "\n",
    "# make an instance of the PrettyMIDI class for drums\n",
    "# Extract drum MIDI data\n",
    "drum_midi = pretty_midi.PrettyMIDI()\n",
    "\n",
    "# make an instance for other insts\n",
    "melody_midi = pretty_midi.PrettyMIDI()\n",
    "\n",
    "for instrument in midi_data.instruments:\n",
    "    if instrument.is_drum:\n",
    "        drum_midi.instruments.append(instrument)\n",
    "    else:\n",
    "        for note in instrument.notes:\n",
    "            note.pitch -= 0 # Manipulate the pitch of the melodies here. For the original pitch, assign 0\n",
    "        melody_midi.instruments.append(instrument)\n",
    "\n",
    "# Convert drum MIDI data to audio\n",
    "drum_audio = drum_midi.fluidsynth(fs=float(_SAMPLING_RATE))\n",
    "\n",
    "# convert melody MIDI data to audio\n",
    "melody_audio = melody_midi.fluidsynth(fs=float(_SAMPLING_RATE))\n",
    "\n",
    "\n",
    "# # Play the drum audio\n",
    "# Audio(drum_audio, rate=_SAMPLING_RATE,)\n",
    "\n",
    "# # Ensure that the length of both audio signals is the same\n",
    "# min_length = min(len(drum_audio), len(melody_audio)) # It calculates the length of each audio signal using the len() function and compares them using the min() function. The purpose of finding the minimum length is to ensure that both audio signals have the same duration. This is necessary because we want to combine them into a single audio signal and play them simultaneously.\n",
    "# drum_audio = drum_audio[:min_length] # These lines ensure that both drum_audio and melody_audio are truncated to the minimum length determined in the previous step.\n",
    "# melody_audio = melody_audio[:min_length] # The [:min_length] slicing operation is used to keep only the samples up to the minimum length for each audio signal. This step is necessary to make sure that both audio signals have the same duration before combining them.\n",
    "\n",
    "# # Combine the audio signals\n",
    "# combined_audio = np.vstack((drum_audio, melody_audio))\n",
    "\n",
    "# # Play the combined audio\n",
    "# sd.play(combined_audio.T, _SAMPLING_RATE)\n",
    "# sd.wait()\n",
    "\n",
    "# Ensure that the length of both audio signals is the same\n",
    "max_length = max(len(drum_audio), len(melody_audio))\n",
    "drum_audio = np.pad(drum_audio, (0, max_length - len(drum_audio)))  # We pad the shorter audio signal with zeros using np.pad() so that both signals have the same length.\n",
    "melody_audio = np.pad(melody_audio, (0, max_length - len(melody_audio))) # We pad the shorter audio signal with zeros using np.pad() so that both signals have the same length.\n",
    "\n",
    "# Create separate stereo channels for each instrument horizontally. This allows us to create separate stereo channels for each instrument.\n",
    "drum_audio_stereo = np.column_stack((drum_audio, np.zeros_like(drum_audio)))\n",
    "melody_audio_stereo = np.column_stack((np.zeros_like(melody_audio), melody_audio))\n",
    "\n",
    "# Combine the stereo channels\n",
    "combined_audio = drum_audio_stereo + melody_audio_stereo\n",
    "\n",
    "# change the playback speed. More details in the note\n",
    "#  _SAMPLING_RATE = _SAMPLING_RATE * 2\n",
    "\n",
    "# Play the combined audio\n",
    "sd.play(combined_audio, _SAMPLING_RATE)\n",
    "sd.wait()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
